{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grayox/refactored-happiness/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jO2L0FKMCdC"
      },
      "source": [
        "## Topic tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2oGsifwL8ID"
      },
      "outputs": [],
      "source": [
        "TOPIC_TREE = {\n",
        "  \"Health & Fitness\": {\n",
        "    \"Nutrition\": {\n",
        "      \"Keto\": {},\n",
        "      \"Paleo\": {},\n",
        "      \"Intermittent Fasting\": {},\n",
        "      \"Clean Eating\": {},\n",
        "      \"Vegan\": {},\n",
        "    },\n",
        "    \"Weight Loss\": {\n",
        "      \"Weight Loss for Women\": {},\n",
        "      \"Weight Loss for Men\": {},\n",
        "    },\n",
        "    \"Aging & Anti-Aging\": {},\n",
        "    \"Women's Health\": {\n",
        "      \"Fertility\": {},\n",
        "      \"Pregnancy\": {},\n",
        "      \"Menopause\": {},\n",
        "    }\n",
        "  },\n",
        "  \"Finance & Investing\": {\n",
        "    \"Budgeting & Money Management\": {\n",
        "      \"Getting Out of Debt\": {},\n",
        "      \"Retirement Planning\": {},\n",
        "    },\n",
        "    \"Investing\": {\n",
        "      \"Stocks\": {},\n",
        "      \"Real Estate\": {},\n",
        "      \"Cryptocurrency\": {},\n",
        "    }\n",
        "  },\n",
        "  \"Home & Garden\": {\n",
        "    \"Decorating on a Budget\": {},\n",
        "    \"Landscaping & Outdoor Living\": {\n",
        "      \"Backyard Ideas\": {},\n",
        "      \"Gardening\": {},\n",
        "    },\n",
        "    \"Interior Design\": {},\n",
        "    \"DIY Projects\": {\n",
        "      \"Furniture Building\": {},\n",
        "      \"Home Improvement\": {},\n",
        "    },\n",
        "  },\n",
        "  \"Travel\": {\n",
        "    \"Budget Travel\": {\n",
        "      \"Backpacking\": {},\n",
        "      \"Hostels\": {},\n",
        "      \"Cheap Flights\": {},\n",
        "    },\n",
        "    \"Luxury Travel\": {\n",
        "      \"Hotels\": {},\n",
        "      \"Tours\": {},\n",
        "      \"Cruises\": {},\n",
        "    },\n",
        "    \"Regional Travel\": {\n",
        "      \"Europe\": {},\n",
        "      \"Asia\": {},\n",
        "      \"USA\": {},\n",
        "    },\n",
        "  },\n",
        "  \"Entertainment\": {\n",
        "    \"Sports\": {},\n",
        "    \"Books\": {},\n",
        "    \"Movies\": {},\n",
        "    \"Television\": {},\n",
        "    \"Social Media\": {},\n",
        "  },\n",
        "  \"Parenting & Family\": {\n",
        "    \"Pregnancy\": {\n",
        "      \"Fertility\": {},\n",
        "    },\n",
        "    \"Babies & Toddlers\": {},\n",
        "    \"Child Development & Education\": {},\n",
        "    \"Special Needs Children\": {},\n",
        "  },\n",
        "  \"Pets\": {\n",
        "    \"Dogs\": {},\n",
        "    \"Cats\": {},\n",
        "    \"Fish & Aquariums\": {},\n",
        "    \"Birds\": {},\n",
        "    \"Exotic Pets\": {},\n",
        "    \"Pet Health\": {\n",
        "      \"Pet Nutrition\": {},\n",
        "      \"Veterinary Advice\": {},\n",
        "    },\n",
        "  },\n",
        "  \"Technology\": {\n",
        "    \"Gadgets & Gear\": {\n",
        "      \"Smart Home\": {},\n",
        "      \"Drones\": {},\n",
        "      \"Smart Phones\": {},\n",
        "    },\n",
        "    \"Apps & Software\": {},\n",
        "    \"Artificial Intelligence\": {},\n",
        "    \"Virtual Reality\": {},\n",
        "  },\n",
        "  \"Automotive\": {\n",
        "    \"Car Reviews\": {},\n",
        "    \"Auto Repair\": {},\n",
        "    \"Customization & Accessories\": {},\n",
        "  },\n",
        "  \"Sports & Outdoors\": {\n",
        "    \"Hiking & Camping\": {},\n",
        "    \"Hunting & Fishing\": {},\n",
        "    \"Extreme Sports\": {},\n",
        "  },\n",
        "  \"Arts & Crafts\": {\n",
        "    \"Knitting & Crochet\": {},\n",
        "    \"Scrapbooking\": {},\n",
        "    \"DIY Crafts\": {\n",
        "      \"Candles\": {},\n",
        "      \"Jewelry Making\": {},\n",
        "      \"Soaps\": {},\n",
        "    }\n",
        "  },\n",
        "  \"Beauty & Fashion\": {\n",
        "    \"Makeup & Cosmetics\": {},\n",
        "    \"Skin & Anti-Aging\": {},\n",
        "    \"Hair Care\": {\n",
        "      \"Hairstyles\": {},\n",
        "      \"Hair Loss\": {},\n",
        "    },\n",
        "    \"Plus-size Fashion\": {}\n",
        "  },\n",
        "  \"Food & Cooking\": {\n",
        "    \"Recipes\": {\n",
        "      \"Desserts\": {},\n",
        "      \"Healthy Meals\": {},\n",
        "      \"On a Budget\": {},\n",
        "      \"Instant Pot\": {},\n",
        "      \"Grilling\": {},\n",
        "      \"Vegan\": {},\n",
        "      \"Keto\": {},\n",
        "    },\n",
        "    \"Restaurants\": {}\n",
        "  },\n",
        "  \"Home Improvement\": {\n",
        "    \"Plumbing\": {},\n",
        "    \"Electrical\": {},\n",
        "    \"HVAC\": {},\n",
        "    \"Flooring\": {},\n",
        "    \"Bathroom Remodel\": {},\n",
        "    \"Kitchen Remodel\": {},\n",
        "    \"Roofing\": {},\n",
        "    \"Appliance Repair\": {\n",
        "        \"Washing Machines & Dryers\": {},\n",
        "        \"Dishwashers\": {},\n",
        "        \"Refrigerators\": {},\n",
        "    },\n",
        "  },\n",
        "  \"Education & Learning\": {\n",
        "    \"Homeschooling\": {},\n",
        "    \"Studying Tips\": {\n",
        "      \"Memory\": {},\n",
        "      \"Focus\": {},\n",
        "      \"Accelerated Learning\": {}\n",
        "    },\n",
        "    \"Writing Help\": {\n",
        "      \"Essay Writing\": {},\n",
        "      \"Research Papers\": {}\n",
        "    }\n",
        "  },\n",
        "  \"Lifestyle\": {\n",
        "    \"Sustainability & Green Living\": {\n",
        "      \"Zero Waste Home\": {},\n",
        "      \"Tiny House Living\": {},\n",
        "      \"Eco-Friendly Products\": {},\n",
        "    },\n",
        "    \"Minimalism\": {\n",
        "      \"Organization\": {},\n",
        "      \"Essentialism\": {},\n",
        "      \"Living with Less\": {},\n",
        "    },\n",
        "    \"Self-Care & Wellness\": {\n",
        "      \"Yoga\": {},\n",
        "      \"Meditation\": {},\n",
        "      \"Life Coaching\": {},\n",
        "      \"Aromatherapy\": {\n",
        "        \"Essential Oils\": {},\n",
        "      },\n",
        "    },\n",
        "    \"Online Business\": {\n",
        "      \"Affiliate Marketing\": {},\n",
        "      \"Blogging for Profit\": {},\n",
        "      \"Side Hustles\": {},\n",
        "    },\n",
        "    \"Art & Culture\": {\n",
        "      \"Visual Arts\": {\n",
        "        \"Painting\": {},\n",
        "        \"Sculpture\": {},\n",
        "        \"Photography\": {},\n",
        "      },\n",
        "      \"Performing Arts\": {\n",
        "        \"Dance\": {},\n",
        "        \"Theater\": {},\n",
        "        \"Music\": {},\n",
        "      },\n",
        "      \"Literature\": {\n",
        "        \"Fiction Writing\": {},\n",
        "        \"Poetry\": {},\n",
        "      },\n",
        "      \"Film & Media\": {\n",
        "        \"Movies\": {},\n",
        "        \"Television\": {},\n",
        "        \"Video Production\": {},\n",
        "      },\n",
        "      \"Culture\": {\n",
        "        \"Art History\": {},\n",
        "        \"Architecture\": {},\n",
        "      },\n",
        "    },\n",
        "  },\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4K08oldSbNhS"
      },
      "source": [
        "## Topic logic: leaf selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJfFezJqbSdd"
      },
      "outputs": [],
      "source": [
        "class Niche:\n",
        "  def __init__(self, name):\n",
        "    self.name = name\n",
        "    self.details = None\n",
        "\n",
        "def get_random_leaf(tree_node, key_path=None, current_key='',):\n",
        "\n",
        "  if key_path is None:\n",
        "    key_path = []\n",
        "\n",
        "  # Leaf node\n",
        "  # is_node_a_leaf = is_node_a_niche or is_node_empty_dict\n",
        "\n",
        "  # case: niche\n",
        "  is_node_a_niche = isinstance(tree_node, Niche)\n",
        "  if is_node_a_niche:\n",
        "    return (tree_node, key_path,)\n",
        "\n",
        "  # case: {}\n",
        "  is_dict_empty = not tree_node # assuming it's a dict, which is checked later\n",
        "  is_node_a_dict = isinstance(tree_node, dict)\n",
        "  is_node_empty_dict = is_node_a_dict and is_dict_empty\n",
        "  if is_node_empty_dict:\n",
        "    return (current_key, key_path,)\n",
        "\n",
        "  # case: branch\n",
        "  # continue traversing down branches with random key\n",
        "  keys = list(tree_node.keys())\n",
        "  key = random.choice(keys)\n",
        "  key_path.append(key)\n",
        "  next_node = tree_node[key]\n",
        "  return get_random_leaf(tree_node=next_node, key_path=key_path, current_key=key,)\n",
        "\n",
        "# test_get_random_leaf = get_random_leaf(TOPIC_TREE)\n",
        "# print(test_get_random_leaf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45vrhZ329bNP"
      },
      "source": [
        "## Pip installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yMiVmzvh9eaY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b35720fc-c19b-4548-d217-f30d05de9d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/191.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/191.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U tenacity praw html2text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8yQm_dnXqMw"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcuKY9V1Xrv4"
      },
      "outputs": [],
      "source": [
        "import os, requests, json, re, pathlib, textwrap, random, urllib.request\n",
        "# import generation_types\n",
        "\n",
        "# from google.colab import userdata, files\n",
        "import google.generativeai as genai\n",
        "\n",
        "from time import sleep\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "import praw\n",
        "from praw.models import InlineGif, InlineImage, InlineVideo\n",
        "\n",
        "import html2text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r81xHa3dW80E"
      },
      "source": [
        "## API keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2hvjWx2IKzB"
      },
      "outputs": [],
      "source": [
        "# Used to securely store your API key\n",
        "# gemini_api_key = userdata.get('GEMINI_API_KEY')\n",
        "# pixabay_api_key = userdata.get('PIXABAY_API_KEY')\n",
        "# wordpress_username = userdata.get('WORDPRESS_USERNAME')\n",
        "# wordpress_password = userdata.get('WORDPRESS_PASSWORD')\n",
        "# wordpress_client_id = userdata.get('WORDPRESS_CLIENT_ID')\n",
        "# wordpress_client_secret = userdata.get('WORDPRESS_CLIENT_SECRET')\n",
        "# reddit_client_id = userdata.get('REDDIT_CLIENT_ID')\n",
        "# reddit_client_secret = userdata.get('REDDIT_CLIENT_SECRET')\n",
        "# reddit_user_agent = userdata.get('REDDIT_USER_AGENT')\n",
        "# reddit_username = userdata.get('REDDIT_USERNAME')\n",
        "# reddit_password = userdata.get('REDDIT_PASSWORD')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gemini_api_key = os.environ['GEMINI_API_KEY']\n",
        "pixabay_api_key = os.environ['PIXABAY_API_KEY']\n",
        "wordpress_username = os.environ['WORDPRESS_USERNAME']\n",
        "wordpress_password = os.environ['WORDPRESS_PASSWORD']\n",
        "wordpress_client_id = os.environ['WORDPRESS_CLIENT_ID']\n",
        "wordpress_client_secret = os.environ['WORDPRESS_CLIENT_SECRET']\n",
        "reddit_client_id = os.environ['REDDIT_CLIENT_ID']\n",
        "reddit_client_secret = os.environ['REDDIT_CLIENT_SECRET']\n",
        "reddit_user_agent = os.environ['REDDIT_USER_AGENT']\n",
        "reddit_username = os.environ['REDDIT_USERNAME']\n",
        "reddit_password = os.environ['REDDIT_PASSWORD']"
      ],
      "metadata": {
        "id": "k-PckVw1HuKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI8_VpLFW5bA"
      },
      "source": [
        "## Pixabay for stock images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFAUHpV-HZNm"
      },
      "outputs": [],
      "source": [
        "def get_pixabay_image_url_from_search(search_query,):\n",
        "  \"\"\"\n",
        "  Gets the URL of an image from Pixabay that matches the given search query.\n",
        "\n",
        "  Args:\n",
        "    search_query: The search query to use when searching for images.\n",
        "\n",
        "  Returns:\n",
        "    The URL of an image from Pixabay that matches the given search query, or None\n",
        "    if no images were found.\n",
        "  \"\"\"\n",
        "\n",
        "  FALLBACK_SEARCH_TERM = 'smile'\n",
        "\n",
        "  base_url = 'https://pixabay.com/api/'\n",
        "  params = {\n",
        "    'key': pixabay_api_key,\n",
        "    'q': search_query,\n",
        "    'image_type': 'photo',\n",
        "    'per_page': 200,\n",
        "    'editors_choice': True,\n",
        "    'asset_type': 'image',\n",
        "    'image_type': 'photo',\n",
        "    'order': 'popular', # 'latest'\n",
        "    'limit': 200,\n",
        "    'safesearch': True,\n",
        "    # 'category': category, # backgrounds, fashion, nature, science, education, feelings, health, people, religion, places, animals, industry, computer, food, sports, transportation, travel, buildings, business, music\n",
        "  }\n",
        "\n",
        "  image_url = False\n",
        "  response = requests.get(base_url, params=params)\n",
        "\n",
        "  # Check if the request was successful.\n",
        "  if response.status_code == 200:\n",
        "    data = response.json()\n",
        "    print(data)\n",
        "\n",
        "    # Check if the \"hits\" key is present in the response JSON.\n",
        "    if 'hits' in data:\n",
        "      # Get random image from results\n",
        "      try:\n",
        "        total_hits = data['totalHits']\n",
        "        if(total_hits == 0):\n",
        "          return False\n",
        "        random_hit = random.randint(0, total_hits-1)\n",
        "        # asset = data['hits'][0]\n",
        "        asset = data['hits'][random_hit]\n",
        "        image_url = asset['webformatURL']\n",
        "      except IndexError:\n",
        "        if 'hits' not in data or len(data['hits']) == 0:\n",
        "          print(f\"No hits for search query: {search_query}\")\n",
        "          search_query = FALLBACK_SEARCH_TERM # fallback search term\n",
        "          return get_pixabay_image_url_from_search(search_query)\n",
        "    else:\n",
        "      print('No assets found.')\n",
        "  else:\n",
        "    print('Request failed with status code:', response.status_code)\n",
        "\n",
        "  if not image_url:\n",
        "    image_url = get_pixabay_image_url_from_search(FALLBACK_SEARCH_TERM)\n",
        "\n",
        "  # Return the assets list.\n",
        "  return image_url\n",
        "# get_pixabay_image_url_from_search('flower')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndHgFEhkfIyr"
      },
      "source": [
        "## Config LLM API + Tenacity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-w9NHZeF-1U"
      },
      "outputs": [],
      "source": [
        "from tenacity import *\n",
        "\n",
        "MAX_RETRIES = 12\n",
        "LLM_MODEL_NAME = 'gemini-pro'\n",
        "WAIT_TIME_IN_SECONDS_BETWEEN_RETRIES = 3\n",
        "\n",
        "# initialize google gemini\n",
        "# https://colab.research.google.com/drive/1N3PQgaP9FtaFSMD7jZ0ymGpXlGWyhFmh#scrollTo=2bcfnGEviwTI\n",
        "genai.configure(api_key=gemini_api_key)\n",
        "model = genai.GenerativeModel(model_name=LLM_MODEL_NAME)\n",
        "# model\n",
        "\n",
        "@retry(stop=stop_after_attempt(MAX_RETRIES), wait=wait_fixed(WAIT_TIME_IN_SECONDS_BETWEEN_RETRIES))\n",
        "def get_completion(prompt):\n",
        "  response = model.generate_content(prompt)\n",
        "  # print(f'prompt: {prompt}')\n",
        "  sleep(1)\n",
        "  completion = response.text\n",
        "  # print(f'completion: {completion}')\n",
        "  return completion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjowjeEYfVnA"
      },
      "source": [
        "## Writing prompts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZS99yy3zfX4-"
      },
      "outputs": [],
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
        "\n",
        "# def get_random_niche():\n",
        "#   AFFILIATE_NICHE_CATEGORIES = [ \"Health & Fitness\", \"Finance & Investing\", \"Home & Garden\", \"Travel\", \"Parenting & Family\", \"Self-Improvement\", \"Relationships\", \"Pets\", \"Arts & Crafts\", \"Beauty & Fashion\", \"Food & Cooking\", \"Technology\", \"Automotive\", \"Sports & Outdoors\", \"Education & Learning\", \"Home Improvement\", \"Weddings\", \"Photography\", \"Sustainability & Green Living\", ]\n",
        "#   random_niche = random.choice(AFFILIATE_NICHE_CATEGORIES)\n",
        "\n",
        "# reddit to blog article\n",
        "def get_blog_article_from_reddit_post(original_reddit_post, article_target_length_in_words,):\n",
        "  reddit_to_blog_prompt = f\"\"\"\n",
        "    You are an expert at blog writing and SEO optimization. You will be given a post from Reddit.\n",
        "    The post will contain the original post and some top level comments in JSON format.\n",
        "    Your task is to write a helpful blog article optimized for SEO using the Reddit post as the basis for the blog article.\n",
        "    Your article should be {article_target_length_in_words} words in length.\n",
        "    Format your article with the explicit use of <H1> and <H2> html tags.\n",
        "    ---\n",
        "    REDDIT POST: {original_reddit_post}\n",
        "    ARTICLE:\n",
        "  \"\"\"\n",
        "  blog_article = get_completion(reddit_to_blog_prompt)\n",
        "  return blog_article\n",
        "\n",
        "# reddit to keywords\n",
        "def get_keywords_from_reddit_post(reddit_post):\n",
        "  reddit_to_keywords_prompt = f\"\"\"\n",
        "    You are an expert at blog writing and SEO optimization. You will be given a post from Reddit.\n",
        "    The post will contain the original post and some top level comments in JSON format.\n",
        "    Your task is to extract a set of long tail keywords that a writer will use later to write a blog article based on the Reddit post.\n",
        "    Separate your list of keywords with a comma.\n",
        "    ---\n",
        "    REDDIT POST: {reddit_post}\n",
        "    KEYWORDS:\n",
        "  \"\"\"\n",
        "  keywords = get_completion(reddit_to_keywords_prompt)\n",
        "  return keywords\n",
        "\n",
        "# article to title\n",
        "def get_article_title_from_text(text):\n",
        "  article_to_title_prompt = f\"\"\"\n",
        "    You are an expert at blog writing and SEO optimization. You will be given the text of an article.\n",
        "    Your task is to decide on an appropriate title for the article and ONLY return the title.\n",
        "    Do not include any extra words or additional language that is not part of the title.\n",
        "    ---\n",
        "    ARTICLE TEXT: {text}\n",
        "    TITLE:\n",
        "  \"\"\"\n",
        "    # Numbers as per the listcicle format are often good for titles. Consider using them.\n",
        "  article_title = get_completion(article_to_title_prompt).replace('*', '')\n",
        "  return article_title\n",
        "\n",
        "# extract excerpt\n",
        "def get_article_excerpt_from_text(text):\n",
        "  article_to_excerpt_prompt = f\"\"\"\n",
        "    You are an expert at blog writing and SEO optimization. You will be given the text of an article.\n",
        "    Your task is to extract an engaging excerpt from the text of the article.\n",
        "    Do not label the excerpt as such. Do not use any formatting or quotation marks in your response.\n",
        "    Make the excerpt as brief as possible but in every case, limit the excerpt to no more than 30 words.\n",
        "    ---\n",
        "    ARTICLE TEXT: {text}\n",
        "    EXCERPT:\n",
        "  \"\"\"\n",
        "  article_excerpt = get_completion(article_to_excerpt_prompt)\n",
        "  return article_excerpt\n",
        "\n",
        "# keywords to blog\n",
        "def get_blog_article_from_keywords(keywords, article_target_length_in_words,):\n",
        "  keywords_to_blog_prompt = f\"\"\"\n",
        "    You are an expert at blog writing and SEO optimization. You will be given a long tailed keyword.\n",
        "    Your task is write a helpful informational blog article that is SEO optimized to rank for that longtailed keyword.\n",
        "    Your article should be {article_target_length_in_words} words in length.\n",
        "    Avoid writing articles that could be considered giving legal, financial, investing, tax or medical advice.\n",
        "    Format your article in HTML by explicitly using <title>, <h1> and <h2> tags.\n",
        "    Use <b> and <i> tags where appropriate but DO NOT use markdown like asterisks (* or **).\n",
        "    Make the <h1> tag either be identical to the keywords or contain the keywords. Also, make the <h1> tag identical to the <title> tag.\n",
        "    Your goal should be to keep your title to no more than 60 characters or 11 words while still making it descriptive enough so that users know what they are about to click on.\n",
        "    Avoid the use of generic headings like <h2>Introduction<h2>. Instead, make every heading a very pithy,\n",
        "    punchy thesis statement that summarizes the content block like <h2>Apps foster toddlers' learning.</h2>\n",
        "    Do not select any key words dealing with businesses 'near me' as we want the articles to be informational only and not induce hallucinations.\n",
        "    Cite between 3-5 references using anchor tags and outbound hyperlinks. Use the Vancouver style (a/k/a/ Uniform Requirements Style) for your citations.\n",
        "    In your citations, only link to the main domain home page. No paths or subdomains. This should mitigate against broken links.\n",
        "    ---\n",
        "    NICHE: {keywords}\n",
        "    ARTICLE:\n",
        "  \"\"\"\n",
        "    # Listcicle formats are often good for articles and titles. Consider using them sometimes when appropriate. But they are not mandatory.\n",
        "  blog_article = get_completion(keywords_to_blog_prompt)\n",
        "  return blog_article\n",
        "\n",
        "# niche to keywords\n",
        "def get_keywords_from_niche(niche):\n",
        "  niche_to_keywords_prompt = f\"\"\"\n",
        "    You are an expert at affiliate marketing, blog writing and SEO optimization.\n",
        "    You will be given the name of a niche for affiliate marketing.\n",
        "    Your task is to select a low-competition long-tailed keyword in the niche you are given.\n",
        "    Avoid selecting keywords that might lead to articles that could be considered giving legal, financial, investing, tax or medical advice.\n",
        "    Do not label the keywords as such. Do not use any formatting like markdown, asterisks (* or **)\n",
        "    or quotation marks in your response.\n",
        "    ---\n",
        "    NICHE: {niche}\n",
        "    KEYWORD:\n",
        "  \"\"\"\n",
        "  keywords = get_completion(niche_to_keywords_prompt)\n",
        "  return keywords\n",
        "\n",
        "# article to image search term\n",
        "def get_image_search_term_from_title(article_title):\n",
        "  title_to_search_term_prompt = f\"\"\"\n",
        "    You are an expert at affiliate marketing, blog writing and SEO optimization.\n",
        "    You will be given an article title. Your job is to produce a search term to enter\n",
        "    into Pixabay to find a suitable stock image. It is important that your search term only\n",
        "    include a single word. Some examples include: \"nature\", \"christmas\", \"background\", \"sky\",\n",
        "    \"winter\", \"snow\", \"food\", \"love\", \"cat\", \"forest\", \"flower\"\n",
        "    ---\n",
        "    ARTICLE TITLE: {article_title}\n",
        "    SINGLE-WORD SEARCH TERM:\n",
        "  \"\"\"\n",
        "  search_term = get_completion(title_to_search_term_prompt)\n",
        "  return search_term"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d64h0aETxe0"
      },
      "source": [
        "## Params & settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-x4EcBKTtkz"
      },
      "outputs": [],
      "source": [
        "# docs\n",
        "# https://developer.wordpress.com/docs/oauth2/\n",
        "# https://developer.wordpress.com/docs/api/1.1/post/sites/%24site/posts/new/ - post params, e.g., meta, tags, etc.\n",
        "# https://developer.wordpress.org/rest-api/reference/posts # new docs (v2)\n",
        "\n",
        "# params\n",
        "# blog\n",
        "SITE_ID = 'xanadu6'\n",
        "BLOG_FRIENDLY_NAME = 'Xanadu'\n",
        "site_url = f'{SITE_ID}.wordpress.com'\n",
        "BASE_URL = 'https://public-api.wordpress.com/rest/v1/'\n",
        "# reddit\n",
        "TARGET_SUBREDDIT = 'Xanadu6'\n",
        "\n",
        "# settings\n",
        "TARGET_NUMBER_OF_POSTS = 1\n",
        "INCLUDE_REDDIT = False\n",
        "ARTICLE_TARGET_LENGTH_IN_WORDS = 1500\n",
        "IS_USE_AI_IMAGES = False # True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KwnkpQDxj7l"
      },
      "source": [
        "## Main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgR2HVHvDKt9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54074589-b14a-4aa7-fcdb-d5bce908bf86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "access token: q&jDxiTZ8%mJvrkv@xjD)95L48va!w6GXRLwQrIIxx4YbunpY6ylMP%r7(0a@2X)\n",
            "user data: {'ID': 175448203, 'display_name': 'Kubla Khan', 'username': 'xanadu6', 'email': 'qquestlive@gmail.com', 'primary_blog': 227139296, 'primary_blog_url': 'http://xanadu6.wordpress.com', 'primary_blog_is_jetpack': False, 'has_jetpack_partner_access': False, 'language': 'en', 'locale_variant': '', 'token_site_id': False, 'token_scope': ['global'], 'avatar_URL': 'https://1.gravatar.com/avatar/19afeb542a4ea8391c10258a1118f869e95455d926cb191e3f116e16f237168d?s=96&d=identicon', 'profile_URL': 'http://gravatar.com/xanadu6', 'verified': True, 'email_verified': True, 'date': '2019-11-21T19:41:44+00:00', 'site_count': 2, 'jetpack_site_count': 0, 'visible_site_count': 2, 'jetpack_visible_site_count': 0, 'has_unseen_notes': True, 'newest_note_type': 'view_milestone', 'phone_account': False, 'meta': {'links': {'self': 'https://public-api.wordpress.com/rest/v1/me', 'help': 'https://public-api.wordpress.com/rest/v1/me/help', 'site': 'https://public-api.wordpress.com/rest/v1/sites/5836086', 'flags': 'https://public-api.wordpress.com/rest/v1/me/flags'}, 'marketing_price_group': False, 'plans_reorder_abtest_variation': 'control'}, 'is_valid_google_apps_country': True, 'user_ip_country_code': 'TW', 'social_login_connections': [{'service': 'google', 'service_user_email': 'qquestlive@gmail.com', 'service_user_id': '118025553961691347072'}], 'social_signup_service': 'google', 'abtests': {}, 'i18n_empathy_mode': False, 'use_fallback_for_incomplete_languages': False, 'is_google_domain_owner': False, 'had_hosting_trial': False}\n",
            "niche: Meditation\n",
            "categories_path: ['Lifestyle', 'Self-Care & Wellness', 'Meditation']\n"
          ]
        }
      ],
      "source": [
        "# get auth header\n",
        "def get_auth_header(access_token):\n",
        "  return {'Authorization': f'Bearer {access_token}'}\n",
        "\n",
        "# get access token\n",
        "def get_access_token():\n",
        "  url = 'https://public-api.wordpress.com/oauth2/token'\n",
        "\n",
        "  credentials = {\n",
        "    'username': wordpress_username,\n",
        "    'password': wordpress_password,\n",
        "    'client_id': wordpress_client_id,\n",
        "    'client_secret': wordpress_client_secret,\n",
        "    'grant_type': 'password',\n",
        "  }\n",
        "\n",
        "  response = requests.post(url, data=credentials,)\n",
        "\n",
        "  auth = json.loads(response.text)\n",
        "  access_token = auth['access_token']\n",
        "  # print(access_token)\n",
        "  return access_token\n",
        "\n",
        "# get user data\n",
        "def get_user_data(access_token):\n",
        "  endpoint = f'{BASE_URL}me/'\n",
        "  headers = get_auth_header(access_token)\n",
        "  response = requests.get(endpoint, headers=headers,)\n",
        "\n",
        "  user_data = response.json()\n",
        "  # print(user_data)\n",
        "  return user_data\n",
        "\n",
        "# utility function for kebab case for slug\n",
        "def get_kebab_case(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r\"[\\W_]+\", \"-\", text)\n",
        "  return text\n",
        "# print(get_kebab_case(\"Test String\")) # prints \"test-string\"\n",
        "# print(get_kebab_case(\"Random Text Here\")) # prints \"random-text-here\"\n",
        "\n",
        "# post request\n",
        "def set_new_post(access_token, article_target_length_in_words, is_set_new_reddit_post=False,):\n",
        "\n",
        "  endpoint = f'{BASE_URL}sites/{site_url}/posts/new'\n",
        "  auth_header = get_auth_header(access_token)\n",
        "\n",
        "  # niche = get_random_niche()\n",
        "  niche, categories_path, = get_random_leaf(TOPIC_TREE)\n",
        "\n",
        "  # keywords = 'best nutritional supplements'\n",
        "  print(f'niche: {niche}')\n",
        "  print(f'categories_path: {categories_path}')\n",
        "  keywords = get_keywords_from_niche(niche=niche)\n",
        "  print(f'keywords: {keywords}')\n",
        "  sleep(1)\n",
        "  slug = get_kebab_case(keywords)\n",
        "  sleep(1)\n",
        "  blog_article = get_blog_article_from_keywords(\n",
        "      keywords=keywords,\n",
        "      article_target_length_in_words=article_target_length_in_words,\n",
        "    )\n",
        "  sleep(1)\n",
        "  article_title = get_article_title_from_text(text=blog_article)\n",
        "  sleep(1)\n",
        "  article_excerpt = get_article_excerpt_from_text(text=blog_article)\n",
        "  sleep(1)\n",
        "\n",
        "  files = {}\n",
        "  if IS_USE_AI_IMAGES:\n",
        "    # encoded image from stable diffusion\n",
        "    encoded_image = getStableDiffusionText2Image(article_title,) # base64 encoded string\n",
        "\n",
        "    # image\n",
        "    files = {\n",
        "    # 'media[]': (image_path, open(image_path, 'rb',),),\n",
        "    # 'media[]': ('image.jpg', encoded_image, 'image/jpeg',)\n",
        "    # 'media[]': ('image.jpg', encoded_image.getvalue(), 'image/jpeg')\n",
        "      'media[]': (TEMP_IMAGE_PATH, open(TEMP_IMAGE_PATH, 'rb',),),\n",
        "    }\n",
        "    # # image_data = {\n",
        "    # #   'title': 'Image Post',\n",
        "    # #   'media_attrs[0][caption]': 'My Great Photo'\n",
        "    # # }\n",
        "  else:\n",
        "    # image url from pixabay api\n",
        "    # image_url = image_path\n",
        "    # image_url = random.choice(placeholder_images)\n",
        "    # image_url = get_pixabay_image_url_from_search(search_query=keywords,)\n",
        "    image_search_term = get_image_search_term_from_title(article_title)\n",
        "    print(f'image search term: {image_search_term}')\n",
        "    image_url = get_pixabay_image_url_from_search(image_search_term)\n",
        "\n",
        "  # tags = ['python', 'api']\n",
        "  data = {\n",
        "    # 'title': 'My test title',\n",
        "    'title': article_title,\n",
        "    # 'content': 'Testing test',\n",
        "    'content': blog_article,\n",
        "    # 'slug': 'testing-test-only-test-this-is-a-test-only',\n",
        "    'slug': slug,\n",
        "    'status': 'publish',\n",
        "    # 'categories': [ 'testing', 'tests', 'tested', ],\n",
        "    # 'categories': niche,\n",
        "    'categories': categories_path,\n",
        "    # 'featured_image': image_url, # moved to conditional below\n",
        "    # 'tags': (None, tags,),\n",
        "    'tags': keywords,\n",
        "    'excerpt': article_excerpt,\n",
        "    'publicize': True,\n",
        "\n",
        "    # 'media[0]': open(image_url, 'rb',),\n",
        "    'media_attrs[0][caption]': keywords,\n",
        "  }\n",
        "  if(image_url):\n",
        "    data['featured_image'] = image_url\n",
        "\n",
        "  # # handle error\n",
        "  # if response.status_code != 200:\n",
        "  #   print('Error: Post failed at `response = requests.post()`')\n",
        "  #   print(error)\n",
        "  #   return None\n",
        "  try:\n",
        "    response = requests.post(\n",
        "      endpoint, json=data, headers=auth_header, files=files, # data=image_data,\n",
        "    )\n",
        "    response.raise_for_status()\n",
        "  except requests.exceptions.RequestException as my_error:\n",
        "    print(f'Error: {my_error}')\n",
        "    return None\n",
        "\n",
        "  result = response.json()\n",
        "\n",
        "  # send post to reddit\n",
        "  blog_article_url = result[\"URL\"]\n",
        "  print(f'blog article url: {blog_article_url}')\n",
        "\n",
        "  blog_article_in_markdown = html2text.html2text(blog_article)\n",
        "  blog_article_plus_link_to_source = f'Source: [{BLOG_FRIENDLY_NAME} blog]({blog_article_url})\\n\\n\\n{blog_article_in_markdown}'\n",
        "  print(f'image url: {image_url}')\n",
        "  # urllib.request.urlretrieve(image_url, TEMP_IMAGE_PATH) # save image to local file\n",
        "\n",
        "  if is_set_new_reddit_post:\n",
        "    reddit_post = set_post_to_reddit(\n",
        "      subreddit=TARGET_SUBREDDIT,\n",
        "      title=article_title,\n",
        "      selftext=blog_article_plus_link_to_source,\n",
        "      # image_path=TEMP_IMAGE_PATH,\n",
        "      # image_caption=article_excerpt,\n",
        "    )\n",
        "\n",
        "  # print(result)\n",
        "  return result\n",
        "\n",
        "def set_new_posts(access_token, target_number_of_posts, article_target_length_in_words, is_set_new_reddit_post=False,):\n",
        "  for i in range(target_number_of_posts):\n",
        "    new_post = set_new_post(\n",
        "        access_token=access_token,\n",
        "        article_target_length_in_words=article_target_length_in_words,\n",
        "        is_set_new_reddit_post=is_set_new_reddit_post,\n",
        "      )\n",
        "    print(f'new post: {new_post}')\n",
        "    sleep(8)\n",
        "\n",
        "def main():\n",
        "  access_token = get_access_token()\n",
        "  print(f'access token: {access_token}')\n",
        "  user_data = get_user_data(access_token)\n",
        "  print(f'user data: {user_data}')\n",
        "  set_new_posts(\n",
        "      access_token=access_token,\n",
        "      target_number_of_posts=TARGET_NUMBER_OF_POSTS,\n",
        "      article_target_length_in_words=ARTICLE_TARGET_LENGTH_IN_WORDS,\n",
        "      is_set_new_reddit_post=INCLUDE_REDDIT,\n",
        "    )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfqjBkKdSHLMXMlhIvTAAz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}